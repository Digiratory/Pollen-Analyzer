{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a13fc6-90ea-411e-9edb-7b9a09a0ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray[tune]\n",
    "# !pip install grpcio\n",
    "# !pip install grpcio-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84cbdfc-531c-4dd1-b89a-d441decf8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tempfile\n",
    "import lightning.pytorch as pl\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from filelock import FileLock\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.train.lightning import (\n",
    "    RayDDPStrategy,\n",
    "    RayLightningEnvironment,\n",
    "    RayTrainReportCallback,\n",
    "    prepare_trainer,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076a1cda-411f-4636-b438-f28706578fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sm_50', 'sm_60', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_37', 'sm_90']\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9af2e2-473f-4c83-b9f1-ba53d724be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6edf17cd-926e-4422-aeab-b796b9fe2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTS_ROOT = r\"/home/shared/datasets/pollen_dataset_2024_05_08_objects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82bbf52-1ef9-4c3e-a95b-005398cab27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All known classes: ['Quercus', 'Tilia', 'Corylus', 'Acer', 'Populus tremula', 'Betula', 'Alnus', 'Pinus', 'Salix']\n",
      "Train classes: ['Acer', 'Salix', 'Populus tremula', 'Corylus', 'Alnus']\n",
      "Validation classes: ['Betula', 'Quercus']\n",
      "Test classes: ['Pinus', 'Tilia']\n",
      "\n",
      "Load Train Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000cd33986d246688509ffe608c828cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 samples in the class Acer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cefd07b66f488b9efafc162aa431a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d2556e09ef485880365f2e936f2759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 samples in the class Alnus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111b9698ef9b4a72bc5551a62b6dcd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a9c49f5539488db8dd4dc0a5fd4d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 samples in the class Corylus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1574fb949c194d6b9fe8c7a74836571e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0987da02d8648538f08e0e5c430e9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 samples in the class Populus tremula\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa17a642b30f4da4be996602a4c19f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180fdfdd46d241d5936a9e9cb5abc781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227 samples in the class Salix\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a96c0dbbfa4132a55bb508d2beb3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27c8111cea944e8961ef61aa2a94ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 913\n",
      "\n",
      "Load Validation Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3f796b28cf44a3b8912c6ed7eea244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 samples in the class Betula\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd76b50cd98b4a83b08b3c6e5d2390f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/206 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f829588b3af4ea6b6ef9aba42379f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/206 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 samples in the class Quercus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bd7155ec44489db3734d9e15e20098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7156bb99b4e4341aa32ffff6629e519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 296\n",
      "\n",
      "Load Test Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dba51012f4b4f20a1f9170e0d904c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 samples in the class Pinus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b901b7c63fb74cbe9d8307cfe6c421cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c903f01028409792bb54a6c8f687d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 samples in the class Tilia\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9736a877c54d0db34e0f8a03a11397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f35a142e40d4bf79b65eb89e5cbd0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 181\n"
     ]
    }
   ],
   "source": [
    "def pad2size(image, size=(224, 224)):\n",
    "    return ImageOps.fit(image, size)\n",
    "\n",
    "class PollenTripletDataset(Dataset):\n",
    "    def __init__(self, img_dir, classes, \n",
    "                 static_transform=None, \n",
    "                 random_transform=None,\n",
    "                inflation_rate=1):\n",
    "        self.known_classes = classes\n",
    "        self.known_classes.sort()\n",
    "        self.transform = random_transform\n",
    "        self._images = {}\n",
    "        self._labels = {}\n",
    "        self.inflation_rate=inflation_rate\n",
    "\n",
    "        total_samples = 0\n",
    "        for c in tqdm(self.known_classes):\n",
    "            self._images[c] = glob(os.path.join(img_dir, c, \"*.png\"))\n",
    "            print(f\"{len(self._images[c])} samples in the class {c}\")\n",
    "            total_samples += len(self._images[c])\n",
    "            self._images[c] = [ Image.open(img_path) for img_path in tqdm(self._images[c])] \n",
    "            self._labels[c] = [c] * len(self._images[c])  # Метки остаются строками\n",
    "            if static_transform is not None:\n",
    "                self._images[c] = [ static_transform(img) for img in tqdm(self._images[c])] \n",
    "        print(f\"Total samples: {total_samples}\")\n",
    "        self._images = list(self._images.values())\n",
    "        self._labels = list(self._labels.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._images) * self.inflation_rate\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self._images)\n",
    "        anchor = random.choice(self._images[idx])\n",
    "        label = self._labels[idx][0]\n",
    "        positive = random.choice(self._images[idx])\n",
    "        neg_weights = [1]*len(self._images)\n",
    "        neg_weights[idx] = 0\n",
    "        negative = random.choices(self._images, weights=neg_weights)[0]\n",
    "        negative = random.choice(negative)\n",
    "        \n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative, label\n",
    "\n",
    "\n",
    "known_classes = os.listdir(OBJECTS_ROOT)\n",
    "\n",
    "print(f\"All known classes: {known_classes}\")\n",
    "train_classes, test_classes = train_test_split(known_classes, test_size=0.2, random_state=42)\n",
    "train_classes, val_classes = train_test_split(train_classes, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train classes: {train_classes}\")\n",
    "print(f\"Validation classes: {val_classes}\")\n",
    "print(f\"Test classes: {test_classes}\")\n",
    "\n",
    "input_size=(224, 224)\n",
    "\n",
    "static_transforms = v2.Compose([\n",
    "    v2.Lambda(pad2size),\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "print(\"\\nLoad Train Dataset\")\n",
    "dataset_train = PollenTripletDataset(OBJECTS_ROOT, train_classes, static_transform=static_transforms, inflation_rate=100)\n",
    "print(\"\\nLoad Validation Dataset\")\n",
    "dataset_val = PollenTripletDataset(OBJECTS_ROOT, val_classes, static_transform=static_transforms, inflation_rate=100)\n",
    "print(\"\\nLoad Test Dataset\")\n",
    "dataset_test = PollenTripletDataset(OBJECTS_ROOT, test_classes, static_transform=static_transforms, inflation_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7686000-deb2-47ec-a806-e0f204f20fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size= 16,\n",
    "    shuffle= True,\n",
    "    num_workers= 6\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset_val, \n",
    "    batch_size= 4,\n",
    "    shuffle= True,\n",
    "    num_workers= 6\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset_test, \n",
    "    batch_size= 1,\n",
    "    shuffle= True,\n",
    "    num_workers= 6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23256cb4-2979-4c03-bf5b-151ad28b9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, backbone, embedings):\n",
    "        super().__init__()\n",
    "        if backbone == \"resnet18\":\n",
    "            self.model = models.resnet18(weights='DEFAULT')\n",
    "        elif backbone == \"resnet34\":\n",
    "            self.model = models.resnet34(weights='DEFAULT')\n",
    "        elif backbone == \"resnet50\":\n",
    "            self.model = models.resnet50(weights='DEFAULT')\n",
    "        elif backbone == \"resnet101\":\n",
    "            self.model = models.resnet101(weights='DEFAULT')\n",
    "        elif backbone == \"resnet152\":\n",
    "            self.model = models.resnet152(weights='DEFAULT')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backbone\")\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.embedings = nn.Linear(num_features, embedings)\n",
    "        self.model.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.embedings(x)\n",
    "        x = nn.functional.normalize(x) # L2 normalization to put all values on a sphere\n",
    "        return x\n",
    "\n",
    "class PollenEmbedingsModule(L.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.optim_lr=config[\"optim_lr\"]\n",
    "        self.model = EmbeddingModel(config[\"backbone\"], config[\"embedings_size\"])\n",
    "        \n",
    "        config[\"check_val\"]=20\n",
    "        config[\"optim_betas\"]=(0.9, 0.999)\n",
    "        config[\"optim_eps\"]=1e-08\n",
    "        config[\"optim_weight_decay\"]=0\n",
    "        # call this to save (arguments) to the checkpoint\n",
    "        self.save_hyperparameters(config)\n",
    "\n",
    "        self.loss_function = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n",
    "        self.best_score = 0\n",
    "        self.best_val_epoch = -1\n",
    "\n",
    "        self.train_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        anchor, positive, negative, label = batch\n",
    "\n",
    "        anchor_out = self.model(anchor)\n",
    "        positive_out = self.model(positive)\n",
    "        negative_out = self.model(negative)\n",
    "        \n",
    "        loss = self.loss_function(anchor_out, positive_out, negative_out)\n",
    "        pred = {\"train_loss\": loss, \"train_number\": len(anchor_out)}\n",
    "        self.train_step_outputs.append(pred)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        outputs = self.train_step_outputs\n",
    "        train_loss, num_items = 0, 0\n",
    "        for output in outputs:\n",
    "            train_loss += output[\"train_loss\"].sum().item()\n",
    "            num_items += output[\"train_number\"]\n",
    "\n",
    "        mean_train_loss = torch.tensor(train_loss / num_items)\n",
    "        self.log(\"train_loss\", mean_train_loss, sync_dist=True)\n",
    "        self.train_losses.append(mean_train_loss.item())\n",
    "        self.train_step_outputs.clear()  # free memory\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        anchor, positive, negative, label = batch\n",
    "\n",
    "        anchor_out = self.model(anchor)\n",
    "        positive_out = self.model(positive)\n",
    "        negative_out = self.model(negative)\n",
    "        \n",
    "        loss = self.loss_function(anchor_out, positive_out, negative_out)\n",
    "\n",
    "        pred = {\"val_loss\": loss, \"val_number\": len(anchor_out)}\n",
    "        self.validation_step_outputs.append(pred)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        outputs = self.validation_step_outputs\n",
    "        val_loss, num_items = 0, 0\n",
    "        for output in outputs:\n",
    "            val_loss += output[\"val_loss\"].sum().item()\n",
    "            num_items += output[\"val_number\"]\n",
    "\n",
    "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        self.val_losses.append(mean_val_loss.item())\n",
    "\n",
    "        tensorboard_logs = {\n",
    "            \"val_loss\": mean_val_loss\n",
    "        }\n",
    "        self.log(\"val_loss\", mean_val_loss, sync_dist=True)\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "\n",
    "        if mean_val_loss > self.best_score:\n",
    "            self.best_score = mean_val_loss\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "\n",
    "        return {\"log\": tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                          lr=self.hparams.optim_lr,\n",
    "                                          betas=self.hparams.optim_betas,\n",
    "                                          eps=self.hparams.optim_eps,\n",
    "                                          weight_decay=self.hparams.optim_weight_decay)\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": ReduceLROnPlateau(self.optimizer, factor=0.1, patience=10),\n",
    "                \"frequency\": self.hparams.check_val,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_losses, label='Train Loss')\n",
    "        plt.plot([i * self.hparams.check_val for i in range(len(self.val_losses))], self.val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Losses')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64cb7607-66f2-47a4-bcf4-87a07a736ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "    \"backbone\": \"resnet50\",\n",
    "    \"optim_lr\": 0.001,\n",
    "    \"embedings_size\": 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c38a16f-4d60-4591-9e6d-f991528b8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    model = PollenEmbedingsModule(config)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        devices=\"auto\",\n",
    "        accelerator=\"auto\",\n",
    "        strategy=RayDDPStrategy(),\n",
    "        callbacks=[RayTrainReportCallback()],\n",
    "        plugins=[RayLightningEnvironment()],\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer = prepare_trainer(trainer)\n",
    "    trainer.fit(model, train_dataloaders=training_loader, val_dataloaders=val_loader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d826b80a-4886-4f21-8a75-24f524da057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"backbone\": tune.choice([\"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\"]),\n",
    "    \"optim_lr\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"embedings_size\": tune.choice([64, 128, 256]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82aa18f5-8091-431a-98d0-d333639fd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum training epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Number of sampls from parameter space\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b2c2c8e-5892-414f-af0e-7ee2a51863f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f7f16c3-011b-4b92-b51a-79f6c2b666a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=1, use_gpu=True, resources_per_worker={\"CPU\": 1, \"GPU\": 1}\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        num_to_keep=2,\n",
    "        checkpoint_score_attribute=\"val_loss\",\n",
    "        checkpoint_score_order=\"min\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff1d601f-b5a7-4c3a-abca-364c1cb62900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "# Define a TorchTrainer without hyper-parameters for Tuner\n",
    "ray_trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed5d829a-a495-46ef-8a51-3a5bd27108c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-21 07:42:50</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:49.93        </td></tr>\n",
       "<tr><td>Memory:      </td><td>14.0/125.7 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 4.000: -0.0427883043885231 | Iter 2.000: -0.22550933063030243 | Iter 1.000: -0.20936702191829681<br>Logical resource usage: 2.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:K80)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                </th><th>train_loop_config/ba\n",
       "ckbone         </th><th style=\"text-align: right;\">    train_loop_config/em\n",
       "bedings_size</th><th style=\"text-align: right;\">           train_loop_config/op\n",
       "tim_lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  step</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_7720c_00000</td><td>TERMINATED</td><td>10.1.147.149:422335</td><td>resnet34</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.00648277</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         160.733</td><td style=\"text-align: right;\"> 0.0729473</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">   160</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TorchTrainer pid=422335)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=422335)\u001b[0m - (ip=10.1.147.149, pid=422453) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m /opt/conda/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m   rank_zero_warn(\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m Missing logger folder: /tmp/ray/session_2024-06-21_07-39-56_023663_420378/artifacts/2024-06-21_07-40-00/TorchTrainer_2024-06-21_07-39-55/working_dirs/TorchTrainer_7720c_00000_0_backbone=resnet34,embedings_size=256,optim_lr=0.0065_2024-06-21_07-40-00/lightning_logs\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m [rank0]:[W Utils.hpp:106] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m   | Name          | Type              | Params\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m ----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m 0 | model         | EmbeddingModel    | 21.4 M\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m 1 | loss_function | TripletMarginLoss | 0     \n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m ----------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m 21.4 M    Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m 21.4 M    Total params\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m 85.664    Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m /opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m   rank_zero_warn(\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m /opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m   return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m /opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1595: PossibleUserWarning: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m   rank_zero_warn(\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m [rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/jovyan/ray_results/TorchTrainer_2024-06-21_07-39-55/TorchTrainer_7720c_00000_0_backbone=resnet34,embedings_size=256,optim_lr=0.0065_2024-06-21_07-40-00/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/jovyan/ray_results/TorchTrainer_2024-06-21_07-39-55/TorchTrainer_7720c_00000_0_backbone=resnet34,embedings_size=256,optim_lr=0.0065_2024-06-21_07-40-00/checkpoint_000001)\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/jovyan/ray_results/TorchTrainer_2024-06-21_07-39-55/TorchTrainer_7720c_00000_0_backbone=resnet34,embedings_size=256,optim_lr=0.0065_2024-06-21_07-40-00/checkpoint_000002)\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/jovyan/ray_results/TorchTrainer_2024-06-21_07-39-55/TorchTrainer_7720c_00000_0_backbone=resnet34,embedings_size=256,optim_lr=0.0065_2024-06-21_07-40-00/checkpoint_000003)\n",
      "\u001b[36m(RayTrainWorker pid=422453)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/jovyan/ray_results/TorchTrainer_2024-06-21_07-39-55/TorchTrainer_7720c_00000_0_backbone=resnet34,embedings_size=256,optim_lr=0.0065_2024-06-21_07-40-00/checkpoint_000004)\n",
      "2024-06-21 07:42:50,598\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/jovyan/ray_results/TorchTrainer_2024-06-21_07-39-55' in 0.1861s.\n",
      "2024-06-21 07:42:50,607\tINFO tune.py:1041 -- Total run time: 169.95 seconds (169.74 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "def tune_pollen_asha(num_samples=10):\n",
    "    scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        ray_trainer,\n",
    "        param_space={\"train_loop_config\": search_space},\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            num_samples=num_samples,\n",
    "            scheduler=scheduler,\n",
    "        ),\n",
    "    )\n",
    "    return tuner.fit()\n",
    "\n",
    "results = tune_pollen_asha(num_samples=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b82a20-9d77-4ebb-804c-93af83e017e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'val_loss': 0.07294729351997375, 'train_loss': 0.020982593297958374, 'epoch': 4, 'step': 160},\n",
       "  path='/home/jovyan/ray_results/TorchTrainer_2024-06-21_07-39-55/TorchTrainer_7720c_00000_0_backbone=resnet34,embedings_size=256,optim_lr=0.0065_2024-06-21_07-40-00',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/home/jovyan/ray_results/TorchTrainer_2024-06-21_07-39-55/TorchTrainer_7720c_00000_0_backbone=resnet34,embedings_size=256,optim_lr=0.0065_2024-06-21_07-40-00/checkpoint_000004)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_best_result(metric=\"val_loss\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb610cb-57d6-4235-85d8-20515e496764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
